{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating scheduler pod on cluster. This may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 18:16:56,656 - distributed.deploy.adaptive - INFO - Adaptive scaling started: minimum=0 maximum=inf\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "from dask_kubernetes import KubeCluster, make_pod_spec\n",
    "dask.config.set({\"kubernetes.scheduler-service-type\": \"LoadBalancer\"})\n",
    "worker_template = make_pod_spec(image='holdenk/dask:latest',\n",
    "                         memory_limit='8G', memory_request='8G',\n",
    "                         cpu_limit=1, cpu_request=1)\n",
    "scheduler_template = make_pod_spec(image='holdenk/dask:latest',\n",
    "                         memory_limit='4G', memory_request='4G',\n",
    "                         cpu_limit=1, cpu_request=1)\n",
    "cluster = KubeCluster(pod_template = worker_template, scheduler_pod_template = scheduler_template)\n",
    "cluster.adapt()    # or create and destroy workers dynamically based on workload\n",
    "from dask.distributed import Client\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 18:22:04,327 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n",
      "2022-06-01 18:22:04,328 - distributed.deploy.adaptive - INFO - Adaptive scaling started: minimum=1 maximum=10\n",
      "2022-06-01 18:22:04,328 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<distributed.deploy.adaptive.Adaptive at 0x7effaca4faf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster.adapt(minimum=1, maximum=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compression': 'lz4', 'python': (3, 8, 6), 'pickle-protocol': 5}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.scheduler_comm.comm.handshake_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Create a large array and calculate the mean\n",
    "array = da.ones((1000, 1000, 1000))\n",
    "print(array.mean().compute())  # Should print 1.0|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we know the cluster is doing ok :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Counter:\n",
    "    \"\"\" A simple class to manage an incrementing counter \"\"\"\n",
    "    n = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        self.n = 0\n",
    "\n",
    "    def increment(self):\n",
    "        self.n += 1\n",
    "        return self.n\n",
    "\n",
    "    def add(self, x):\n",
    "        self.n += x\n",
    "        return self.n\n",
    "    \n",
    "    def value(self):\n",
    "        return self.n\n",
    "\n",
    "\n",
    "future = client.submit(Counter, actor=True)  # Create a Counter on a worker\n",
    "counter = future.result()     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Actor: Counter, key=Counter-cba9a5b0-ab0c-4f5a-be42-bf493967b24a>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ActorFuture>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.increment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.value().result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.bag as db\n",
    "b = db.from_sequence(range(0, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::result_future_not_ser[]\n",
    "def inc(x):\n",
    "    import time\n",
    "    time.sleep(x)\n",
    "    f = counter.add(x)\n",
    "    # Note: the actor (in this case `counter`) is serelizable, however the future we get back from it is not\n",
    "    # this is likely because the future contains a network connection to the actor, so need to get it's\n",
    "    # concrete value here. If we don't need the value you can avoid blocking and it will still execute.\n",
    "    return f.result()\n",
    "#end::result_future_not_ser[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = client\n",
    "futures = list(map(lambda x: c.submit(inc, x), range(10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Future: finished, type: int, key: inc-3ff4b7331b0a49792933bc22d8633ed1>,\n",
       " <Future: pending, key: inc-e125592e8f81119a8312af9e6c0be8e6>,\n",
       " <Future: pending, key: inc-1254cb1c2334d37f8c4249a2837abfb8>,\n",
       " <Future: pending, key: inc-7cbbb37e68d1b3fb8beebb315cfb47d3>,\n",
       " <Future: pending, key: inc-d9d47846dce3864f143865f9681aa9fe>,\n",
       " <Future: pending, key: inc-5b92e0da31d406193dfba147cc22321f>,\n",
       " <Future: pending, key: inc-f6780821931ffb3d0921ec037a84a5e7>,\n",
       " <Future: pending, key: inc-364cd258c135891bd9362e554423563f>,\n",
       " <Future: pending, key: inc-2fe52468e41b3fb1cde763b5be5c980f>,\n",
       " <Future: pending, key: inc-b99ba4d3aaab3ff7a055b7001d3a37d8>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.value().result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 18:22:49,341 - distributed.deploy.adaptive - INFO - Retiring workers [4, 5]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "futures[5].result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter.value().result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tag::make_account[]\n",
    "class BankAccount:\n",
    "    \"\"\" A bank account actor (similar to counter but with + and -)\"\"\"\n",
    "\n",
    "    # 42 is a good start\n",
    "    def __init__(self, balance=42.0):\n",
    "        self._balance = balance\n",
    "\n",
    "    def deposit(self, amount):\n",
    "        if amount < 0:\n",
    "            raise Exception(\"Can not deposit negative amount\")\n",
    "        self._balance += amount\n",
    "        return self._balance\n",
    "\n",
    "    def withdrawl(self, amount):\n",
    "        if amount > self._balance:\n",
    "            raise Exception(\"Please deposit more money first.\")\n",
    "        self._balance -= amount\n",
    "        return self._balance\n",
    "\n",
    "    def balance(self):\n",
    "        return self._balance\n",
    "\n",
    "\n",
    "account_future = client.submit(BankAccount, actor=True)  # Create a BankAccount on a worker\n",
    "account = account_future.result()\n",
    "#end::make_account[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please deposit more money first.\n"
     ]
    }
   ],
   "source": [
    "#tag::use_account[]\n",
    "# Non-blocking\n",
    "balance_future = account.balance()\n",
    "# Blocks\n",
    "balance = balance_future.result()\n",
    "try:\n",
    "    f = account.withdrawl(100)\n",
    "    f.result() # throws an exception\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "#end::use_account[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = account.withdrawl(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-06-01 18:22:51,340 - distributed.deploy.adaptive - INFO - Retiring workers [0, 1]\n",
      "2022-06-01 18:23:15,340 - distributed.deploy.adaptive - INFO - Retiring workers [2]\n",
      "2022-06-01 18:23:16,341 - distributed.deploy.adaptive - INFO - Retiring workers [3]\n",
      "2022-06-08 12:32:34,145 - distributed.deploy.adaptive_core - ERROR - Adaptive stopping due to error\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tornado/iostream.py\", line 867, in _read_to_buffer\n",
      "    bytes_read = self.read_from_fd(buf)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tornado/iostream.py\", line 1140, in read_from_fd\n",
      "    return self.socket.recv_into(buf, len(buf))\n",
      "ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 863, in send_recv_from_rpc\n",
      "    result = await send_recv(comm=comm, op=key, **kwargs)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 708, in send_recv\n",
      "    response = await comm.read(deserializers=deserializers)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 242, in read\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 148, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <TCP (closed) rpc.adaptive_target local=tcp://10.69.200.180:56334 remote=tcp://23.177.16.199:8786>: ConnectionResetError: [Errno 104] Connection reset by peer\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/deploy/adaptive_core.py\", line 228, in adapt\n",
      "    target = await self.safe_target()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/deploy/adaptive_core.py\", line 159, in safe_target\n",
      "    n = await self.target()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/deploy/adaptive.py\", line 149, in target\n",
      "    return await self.scheduler.adaptive_target(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 866, in send_recv_from_rpc\n",
      "    raise type(e)(\n",
      "distributed.comm.core.CommClosedError: Exception while trying to call remote method 'adaptive_target' before comm was established.\n",
      "2022-06-08 12:32:34,146 - distributed.deploy.adaptive_core - INFO - Adaptive stop\n",
      "2022-06-08 12:34:37,074 - distributed.client - ERROR - Failed to reconnect to scheduler after 30.00 seconds, closing client\n",
      "2022-06-08 12:36:17,896 - distributed.deploy.cluster - WARNING - Failed to sync cluster info multiple times - perhaps there's a connection issue? Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tornado/iostream.py\", line 1205, in connect\n",
      "    self.socket.connect(address)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 491, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 451, in connect\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 148, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7eff57f169d0>: OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/deploy/cluster.py\", line 132, in _sync_cluster_info\n",
      "    await self.scheduler_comm.set_metadata(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 861, in send_recv_from_rpc\n",
      "    comm = await self.live_comm()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 818, in live_comm\n",
      "    comm = await connect(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://23.177.16.199:8786 after 30 s\n",
      "2022-06-08 13:43:54,726 - distributed.deploy.cluster - WARNING - Failed to sync cluster info multiple times - perhaps there's a connection issue? Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/tornado/iostream.py\", line 1205, in connect\n",
      "    self.socket.connect(address)\n",
      "OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/core.py\", line 289, in connect\n",
      "    comm = await asyncio.wait_for(\n",
      "  File \"/opt/conda/lib/python3.8/asyncio/tasks.py\", line 491, in wait_for\n",
      "    return fut.result()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 451, in connect\n",
      "    convert_stream_closed_error(self, e)\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/tcp.py\", line 148, in convert_stream_closed_error\n",
      "    raise CommClosedError(f\"in {obj}: {exc.__class__.__name__}: {exc}\") from exc\n",
      "distributed.comm.core.CommClosedError: in <distributed.comm.tcp.TCPConnector object at 0x7eff57edc520>: OSError: [Errno 101] Network is unreachable\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/deploy/cluster.py\", line 132, in _sync_cluster_info\n",
      "    await self.scheduler_comm.set_metadata(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 861, in send_recv_from_rpc\n",
      "    comm = await self.live_comm()\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/core.py\", line 818, in live_comm\n",
      "    comm = await connect(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/distributed/comm/core.py\", line 315, in connect\n",
      "    raise OSError(\n",
      "OSError: Timed out trying to connect to tcp://23.177.16.199:8786 after 30 s\n"
     ]
    }
   ],
   "source": [
    "f.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
