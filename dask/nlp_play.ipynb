{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bfead8d3-4364-4435-a25d-59d4375f8562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tokenizers\n",
      "  Downloading tokenizers-0.12.1-cp39-cp39-macosx_10_11_x86_64.whl (3.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 3.6 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: tokenizers\n",
      "Successfully installed tokenizers-0.12.1\n"
     ]
    }
   ],
   "source": [
    "!pip install tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1203716a-b958-4933-9924-8db230a74927",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.20.1-py3-none-any.whl (4.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.4 MB 4.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.1.0\n",
      "  Downloading huggingface_hub-0.8.1-py3-none-any.whl (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 10.4 MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (2022.3.15)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: requests in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (2.27.1)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (3.6.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (1.21.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/anaconda3/lib/python3.9/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/anaconda3/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/anaconda3/lib/python3.9/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/anaconda3/lib/python3.9/site-packages (from requests->transformers) (2.0.4)\n",
      "Installing collected packages: huggingface-hub, transformers\n",
      "Successfully installed huggingface-hub-0.8.1 transformers-4.20.1\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64184d73-5c07-482e-b5ee-ce9339bf3727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/anaconda3/lib/python3.9/site-packages (4.64.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d45eeb6-f666-4491-8471-fc3b5ab2785f",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-1.12.0-cp39-none-macosx_10_9_x86_64.whl (133.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 133.6 MB 173 kB/s eta 0:00:013    |████▉                           | 20.1 MB 14.1 MB/s eta 0:00:09     |███████▍                        | 30.9 MB 12.0 MB/s eta 0:00:09     |█████████▊                      | 40.7 MB 13.8 MB/s eta 0:00:074.7 MB/s eta 0:00:10\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/anaconda3/lib/python3.9/site-packages (from torch) (4.1.1)\n",
      "Installing collected packages: torch\n",
      "Successfully installed torch-1.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "47b4bf11-75e0-4e8a-956d-3a4c9a33e7e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/distributed/node.py:177: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 55330 instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "# when working with clusters, specify cluster config, n_workers and worker_size\n",
    "client = Client(n_workers=4, \n",
    "                       threads_per_worker=1,\n",
    "                       memory_limit=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3186dc16-827a-4dbe-a924-1bedf59de550",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "import dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ae5fd7-eaef-4e36-944d-65038b7f9fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "390fbcf7-e87d-4e99-998c-32ddbb8746ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\"> </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px;\">Client</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Client-d94c3bfc-06f2-11ed-853f-acde48001122</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "\n",
       "        <tr>\n",
       "        \n",
       "            <td style=\"text-align: left;\"><strong>Connection method:</strong> Cluster object</td>\n",
       "            <td style=\"text-align: left;\"><strong>Cluster type:</strong> distributed.LocalCluster</td>\n",
       "        \n",
       "        </tr>\n",
       "\n",
       "        \n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55330/status\" target=\"_blank\">http://127.0.0.1:55330/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\"></td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        </table>\n",
       "\n",
       "        \n",
       "            <details>\n",
       "            <summary style=\"margin-bottom: 20px;\"><h3 style=\"display: inline;\">Cluster Info</h3></summary>\n",
       "            <div class=\"jp-RenderedHTMLCommon jp-RenderedHTML jp-mod-trusted jp-OutputArea-output\">\n",
       "    <div style=\"width: 24px; height: 24px; background-color: #e1e1e1; border: 3px solid #9D9D9D; border-radius: 5px; position: absolute;\">\n",
       "    </div>\n",
       "    <div style=\"margin-left: 48px;\">\n",
       "        <h3 style=\"margin-bottom: 0px; margin-top: 0px;\">LocalCluster</h3>\n",
       "        <p style=\"color: #9D9D9D; margin-bottom: 0px;\">3b9b718f</p>\n",
       "        <table style=\"width: 100%; text-align: left;\">\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:55330/status\" target=\"_blank\">http://127.0.0.1:55330/status</a>\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Workers:</strong> 4\n",
       "                </td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total threads:</strong> 4\n",
       "                </td>\n",
       "                <td style=\"text-align: left;\">\n",
       "                    <strong>Total memory:</strong> 0 B\n",
       "                </td>\n",
       "            </tr>\n",
       "            \n",
       "            <tr>\n",
       "    <td style=\"text-align: left;\"><strong>Status:</strong> running</td>\n",
       "    <td style=\"text-align: left;\"><strong>Using processes:</strong> True</td>\n",
       "</tr>\n",
       "\n",
       "            \n",
       "        </table>\n",
       "\n",
       "        <details>\n",
       "            <summary style=\"margin-bottom: 20px;\">\n",
       "                <h3 style=\"display: inline;\">Scheduler Info</h3>\n",
       "            </summary>\n",
       "\n",
       "            <div style=\"\">\n",
       "    <div>\n",
       "        <div style=\"width: 24px; height: 24px; background-color: #FFF7E5; border: 3px solid #FF6132; border-radius: 5px; position: absolute;\"> </div>\n",
       "        <div style=\"margin-left: 48px;\">\n",
       "            <h3 style=\"margin-bottom: 0px;\">Scheduler</h3>\n",
       "            <p style=\"color: #9D9D9D; margin-bottom: 0px;\">Scheduler-0873273a-0ea7-4443-a3ce-a1945a510593</p>\n",
       "            <table style=\"width: 100%; text-align: left;\">\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Comm:</strong> tcp://127.0.0.1:55331\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Workers:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Dashboard:</strong> <a href=\"http://127.0.0.1:55330/status\" target=\"_blank\">http://127.0.0.1:55330/status</a>\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total threads:</strong> 4\n",
       "                    </td>\n",
       "                </tr>\n",
       "                <tr>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Started:</strong> Just now\n",
       "                    </td>\n",
       "                    <td style=\"text-align: left;\">\n",
       "                        <strong>Total memory:</strong> 0 B\n",
       "                    </td>\n",
       "                </tr>\n",
       "            </table>\n",
       "        </div>\n",
       "    </div>\n",
       "\n",
       "    <details style=\"margin-left: 48px;\">\n",
       "        <summary style=\"margin-bottom: 20px;\">\n",
       "            <h3 style=\"display: inline;\">Workers</h3>\n",
       "        </summary>\n",
       "\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 0</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55347\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55354/status\" target=\"_blank\">http://127.0.0.1:55354/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55336\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-lowktdq8\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 1</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55348\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55351/status\" target=\"_blank\">http://127.0.0.1:55351/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55334\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-blm211kh\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 2</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55349\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55353/status\" target=\"_blank\">http://127.0.0.1:55353/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55335\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-qqdfgyha\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "        <div style=\"margin-bottom: 20px;\">\n",
       "            <div style=\"width: 24px; height: 24px; background-color: #DBF5FF; border: 3px solid #4CC9FF; border-radius: 5px; position: absolute;\"> </div>\n",
       "            <div style=\"margin-left: 48px;\">\n",
       "            <details>\n",
       "                <summary>\n",
       "                    <h4 style=\"margin-bottom: 0px; display: inline;\">Worker: 3</h4>\n",
       "                </summary>\n",
       "                <table style=\"width: 100%; text-align: left;\">\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Comm: </strong> tcp://127.0.0.1:55350\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Total threads: </strong> 1\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Dashboard: </strong> <a href=\"http://127.0.0.1:55352/status\" target=\"_blank\">http://127.0.0.1:55352/status</a>\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Memory: </strong> 0 B\n",
       "                        </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td style=\"text-align: left;\">\n",
       "                            <strong>Nanny: </strong> tcp://127.0.0.1:55337\n",
       "                        </td>\n",
       "                        <td style=\"text-align: left;\"></td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <td colspan=\"2\" style=\"text-align: left;\">\n",
       "                            <strong>Local directory: </strong> /Users/mika.kimmins/projects/scalingpythonml/dask/dask-worker-space/worker-72uyo4gt\n",
       "                        </td>\n",
       "                    </tr>\n",
       "\n",
       "                    \n",
       "\n",
       "                    \n",
       "\n",
       "                </table>\n",
       "            </details>\n",
       "            </div>\n",
       "        </div>\n",
       "        \n",
       "\n",
       "    </details>\n",
       "</div>\n",
       "\n",
       "        </details>\n",
       "    </div>\n",
       "</div>\n",
       "            </details>\n",
       "        \n",
       "\n",
       "    </div>\n",
       "</div>"
      ],
      "text/plain": [
       "<Client: 'tcp://127.0.0.1:55331' processes=4 threads=4>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b8d04-6ad5-417a-a2d3-7fd70c95770f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/facebookresearch/fairseq/blob/main/examples/translation/README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54ddfda-4fa9-4324-b2a6-a48c7802988d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/abhishek/roberta-inference-5-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b90750-2885-4d51-ac79-7b97eb2fe380",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import tokenizers\n",
    "import string\n",
    "from tokenizers.implementations import ByteLevelBPETokenizer\n",
    "from tokenizers.processors import BertProcessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7d0feff-1731-47fe-96cd-19995485e7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.1\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from transformers import( DistilBertConfig,\n",
    "                                           DistilBertForMaskedLM,\n",
    "                                           LineByLineTextDataset, DistilBertTokenizer, \n",
    "                                           DataCollatorForLanguageModeling,\n",
    "                                          Trainer, TrainingArguments, pipeline)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28064fef-eff0-4e8c-8209-72dd4251ad9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1676c661-55ee-4ba5-b737-772dd385aaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from tqdm import tqdm\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a96221f4-b206-47cf-847f-b4f54f207d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 192\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 8\n",
    "EPOCHS = 1\n",
    "# ROBERTA_PATH = \"../input/roberta-base\"\n",
    "# TOKENIZER = tokenizers.ByteLevelBPETokenizer(\n",
    "#     vocab_file=f\"{ROBERTA_PATH}/vocab.json\", \n",
    "#     merges_file=f\"{ROBERTA_PATH}/merges.txt\", \n",
    "#     lowercase=True,\n",
    "#     add_prefix_space=True\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "154a176c-a011-4a08-a396-d8c96bfc9641",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# https://huggingface.co/roberta-base\n",
    "from transformers import RobertaTokenizer, RobertaModel\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "model = RobertaModel.from_pretrained('roberta-base')\n",
    "text = \"Replace me by any text you'd like.\"\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e31ad0-5a96-4771-a14d-4a1ad257cc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/arvissu/roberta-base-inference-v2-0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5546b6be-ac2f-4567-8133-14395a989eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import pickle\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "import torch\n",
    "import transformers\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoModel, AutoTokenizer, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9c5bd8-9186-493f-b8eb-cfdd79c1f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model\n",
    "# download the datasets from kaggle\n",
    "# dataset: https://www.kaggle.com/competitions/feedback-prize-effectiveness/data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6b017fcf-26b0-4bc5-b8d8-45148ffc20e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c118bc75-6c57-466b-ba6e-7eb6d26447cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "FOLDS = 4\n",
    "lr = 2e-5\n",
    "SEED = 2018\n",
    "MAX_LEN = 512\n",
    "BATCH_SIZE = 8\n",
    "accumulation_steps = 4\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db032274-2a5a-4f4e-95f1-8523aa011bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback:\n",
    "    def __init__(self):\n",
    "        self.loss = list()\n",
    "        self.model = list()\n",
    "    \n",
    "    def put(self, model, loss):\n",
    "        self.loss.append(loss)\n",
    "        self.model.append(model)\n",
    "\n",
    "    def get_model(self):\n",
    "        ind = np.argmin(self.loss)\n",
    "        return self.model[ind]\n",
    "\n",
    "    \n",
    "class FeedBackModel(nn.Module):\n",
    "    def __init__(self, model_path):\n",
    "        super(FeedBackModel, self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.linear = nn.Linear(768, 3)\n",
    "\n",
    "    def forward(self, ids, mask):\n",
    "        x = self.model(ids, mask)[0][:, 0, :]\n",
    "        pred = self.linear(x)\n",
    "        return pred\n",
    "\n",
    "\n",
    "class FeedBackDataset(Dataset):\n",
    "    def __init__(self, data, model_path, is_test=False):\n",
    "        self.data = data\n",
    "        self.is_test = is_test\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.data['discourse_text'].values[idx] + ' ' + self.tokenizer.sep_token*2  + ' '  + self.data['essay'].values[idx]\n",
    "        if not self.is_test:\n",
    "            target_value = self.data[y_cols].values[idx]\n",
    "      \n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            truncation=True,\n",
    "            add_special_tokens=True,\n",
    "            max_length=MAX_LEN\n",
    "        )['input_ids'] \n",
    "        \n",
    "                  \n",
    "        mask = [1]*len(inputs) + [0] * (MAX_LEN - len(inputs)) \n",
    "        mask = torch.tensor(mask, dtype=torch.long)\n",
    "        \n",
    "        if len(inputs) != MAX_LEN:\n",
    "            inputs = inputs + [self.tokenizer.pad_token_id] * (MAX_LEN - len(inputs)) \n",
    "        ids = torch.tensor(inputs, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        if self.is_test:\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "            }\n",
    "        \n",
    "        else:\n",
    "            targets = torch.FloatTensor(target_value)\n",
    "            return {\n",
    "                'ids': ids,\n",
    "                'mask': mask,\n",
    "                'targets': targets\n",
    "            }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e2b767a1-31d9-4de0-88b0-ede639bd1579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "042ab23a-2ff4-408e-ab2c-da6b5171eb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "    \"\"\"Return the model and tokenizer\"\"\"\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\")\n",
    "\n",
    "    # tokenizer = RobertaTokenizer.from_pretrained(model_path)\n",
    "    # model = RobertaForSequenceClassification.from_pretrained(model_path, return_dict=True)\n",
    "\n",
    "    return tokenizer, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "190d5af0-5a2e-4bf5-9049-46460181d738",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer, model_loaded = load_model()\n",
    "\n",
    "dmodel = dask.delayed(model_loaded.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353f207e-17ab-47a4-a082-85453c64261a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be6346a4-61b0-4dd0-b322-a1f80fc68cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cols = ['discourse_effectiveness']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "99a1c67e-10f9-44d8-a017-6e7f2dc0f7c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dask portion\n",
    "root_src = \"./kaggle/feedback-prize-effectiveness/\"\n",
    "ESSAY_ROOT_PATH = root_src\n",
    "train_src = root_src + \"train.csv\"\n",
    "ddf = dd.read_csv(train_src)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0da73cd6-a684-4ce1-9006-05eee2e03731",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness  \n",
       "0                Adequate  \n",
       "1                Adequate  \n",
       "2                Adequate  \n",
       "3                Adequate  \n",
       "4                Adequate  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8d2dcaea-d6e7-4d6d-ade3-6644c6f6ea03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def fetchEssay(essay_id: str):\n",
    "#     \"\"\"\n",
    "#     Read the text file of the specific essay_id\n",
    "#     \"\"\"\n",
    "#     essay_path = os.path.join('../input/feedback-prize-effectiveness/train/', essay_id + '.txt')\n",
    "#     essay_text = open(essay_path, 'r').read()\n",
    "#     return essay_text\n",
    "\n",
    "# # maybe?\n",
    "# def fetchEssay_ddf(df, essay_root_path, essay_id: str):\n",
    "#     \"\"\"\n",
    "#     Read the text file of the specific essay_id\n",
    "#     \"\"\"\n",
    "#     essay_path = essay_root_path + \"train/\" + essay_id + \".txt\"\n",
    "#     print(\"opening path\" + essay_path)\n",
    "#     essay_text = open(essay_path, 'r').read()\n",
    "#     return essay_text\n",
    "\n",
    "# # maybe?\n",
    "# def fetchEssay_(r):\n",
    "#     \"\"\"\n",
    "#     Read the text file of the specific essay_id\n",
    "#     \"\"\"\n",
    "#     print(r)\n",
    "#     print(type(r))\n",
    "#     essay_id = r.essay_id\n",
    "#     essay_path = ESSAY_ROOT_PATH + \"train/\" + essay_id + \".txt\"\n",
    "#     print(\"opening path\" + essay_path)\n",
    "#     essay_text = open(essay_path, 'r').read()\n",
    "#     return essay_text\n",
    "\n",
    "# def fetchEssay_2(df):\n",
    "#     \"\"\"\n",
    "#     Read the text file of the specific essay_id\n",
    "#     \"\"\"\n",
    "#     return df.apply(fetchEssay_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d59aa679-7d41-4371-ac19-813f27dffd43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    opening essay: foo\n",
      "1    opening essay: foo\n",
      "Name: essay_id, dtype: object\n",
      "0    opening full path: ./kaggle/feedback-prize-eff...\n",
      "1    opening full path: ./kaggle/feedback-prize-eff...\n",
      "Name: essay_id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# ddf.map_partitions(lambda df: df.assign (essay = open(df.essay_id + \"train/\" + essay_id + \".txt\", 'r').read()   ) )\n",
    "def argh(df):\n",
    "    return df.assign(essay = df['essay_id'])\n",
    "\n",
    "def fetchEssay_map(df):\n",
    "    return df.assign(essay_path = open_essay(df['essay_id']))\n",
    "\n",
    "def open_essay(essay_id):\n",
    "    full_path = ESSAY_ROOT_PATH + \"train/\" + essay_id + \".txt\"\n",
    "    print(\"opening essay: \" + essay_id)\n",
    "    print(\"opening full path: \" + full_path)\n",
    "    return (full_path)\n",
    "    # return open(full_path, 'r').read()\n",
    "\n",
    "# ddf_out = ddf.map_partitions(fetchEssay_map, meta = ('essay', 'f8'))\n",
    "ddf_out = ddf.map_partitions(fetchEssay_map)\n",
    "# ddf_out = ddf.map_partitions(argh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a341af30-2fd1-4b49-9e5f-403a25a9eac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "96aff2cd-94d8-4cfa-ac10-31a5dfb679ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        opening essay: 007ACE74B050\n",
      "1        opening essay: 007ACE74B050\n",
      "2        opening essay: 007ACE74B050\n",
      "3        opening essay: 007ACE74B050\n",
      "4        opening essay: 007ACE74B050\n",
      "                    ...             \n",
      "36760    opening essay: FFA381E58FC6\n",
      "36761    opening essay: FFA381E58FC6\n",
      "36762    opening essay: FFA381E58FC6\n",
      "36763    opening essay: FFA381E58FC6\n",
      "36764    opening essay: FFA381E58FC6\n",
      "Name: essay_id, Length: 36765, dtype: object\n",
      "0        opening full path: ./kaggle/feedback-prize-eff...\n",
      "1        opening full path: ./kaggle/feedback-prize-eff...\n",
      "2        opening full path: ./kaggle/feedback-prize-eff...\n",
      "3        opening full path: ./kaggle/feedback-prize-eff...\n",
      "4        opening full path: ./kaggle/feedback-prize-eff...\n",
      "                               ...                        \n",
      "36760    opening full path: ./kaggle/feedback-prize-eff...\n",
      "36761    opening full path: ./kaggle/feedback-prize-eff...\n",
      "36762    opening full path: ./kaggle/feedback-prize-eff...\n",
      "36763    opening full path: ./kaggle/feedback-prize-eff...\n",
      "36764    opening full path: ./kaggle/feedback-prize-eff...\n",
      "Name: essay_id, Length: 36765, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ddf_out\n",
    "result = ddf_out.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "1137fab5-fa17-49e8-a288-ced07e72e9b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>discourse_id</th>\n",
       "      <th>essay_id</th>\n",
       "      <th>discourse_text</th>\n",
       "      <th>discourse_type</th>\n",
       "      <th>discourse_effectiveness</th>\n",
       "      <th>essay_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0013cc385424</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>Hi, i'm Isaac, i'm going to be writing about h...</td>\n",
       "      <td>Lead</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>./kaggle/feedback-prize-effectiveness/train/00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9704a709b505</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>On my perspective, I think that the face is a ...</td>\n",
       "      <td>Position</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>./kaggle/feedback-prize-effectiveness/train/00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c22adee811b6</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>I think that the face is a natural landform be...</td>\n",
       "      <td>Claim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>./kaggle/feedback-prize-effectiveness/train/00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a10d361e54e4</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>If life was on Mars, we would know by now. The...</td>\n",
       "      <td>Evidence</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>./kaggle/feedback-prize-effectiveness/train/00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>db3e453ec4e2</td>\n",
       "      <td>007ACE74B050</td>\n",
       "      <td>People thought that the face was formed by ali...</td>\n",
       "      <td>Counterclaim</td>\n",
       "      <td>Adequate</td>\n",
       "      <td>./kaggle/feedback-prize-effectiveness/train/00...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   discourse_id      essay_id  \\\n",
       "0  0013cc385424  007ACE74B050   \n",
       "1  9704a709b505  007ACE74B050   \n",
       "2  c22adee811b6  007ACE74B050   \n",
       "3  a10d361e54e4  007ACE74B050   \n",
       "4  db3e453ec4e2  007ACE74B050   \n",
       "\n",
       "                                      discourse_text discourse_type  \\\n",
       "0  Hi, i'm Isaac, i'm going to be writing about h...           Lead   \n",
       "1  On my perspective, I think that the face is a ...       Position   \n",
       "2  I think that the face is a natural landform be...          Claim   \n",
       "3  If life was on Mars, we would know by now. The...       Evidence   \n",
       "4  People thought that the face was formed by ali...   Counterclaim   \n",
       "\n",
       "  discourse_effectiveness                                         essay_path  \n",
       "0                Adequate  ./kaggle/feedback-prize-effectiveness/train/00...  \n",
       "1                Adequate  ./kaggle/feedback-prize-effectiveness/train/00...  \n",
       "2                Adequate  ./kaggle/feedback-prize-effectiveness/train/00...  \n",
       "3                Adequate  ./kaggle/feedback-prize-effectiveness/train/00...  \n",
       "4                Adequate  ./kaggle/feedback-prize-effectiveness/train/00...  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cd230a4c-452e-4ead-8741-22110ff6d6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddf_out.assign(essay_read =lambda x:  open(x.essay_path, 'r').read()   )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "cde54965-5013-4cff-af53-6e49548f7926",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `encode_effectiveness_label`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nTypeError(\"unhashable type: 'Series'\")\n\nTraceback:\n---------\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py\", line 182, in raise_on_meta_error\n    yield\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 6406, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/var/folders/9r/wxrt543d7gl3z6pgpy2pjpp80000gp/T/ipykernel_31814/2204620258.py\", line 10, in encode_effectiveness_label\n    return df.assign(discourse_effectiveness_ = apply_new_label(df['discourse_effectiveness'])  )\n  File \"/var/folders/9r/wxrt543d7gl3z6pgpy2pjpp80000gp/T/ipykernel_31814/2204620258.py\", line 8, in apply_new_label\n    return new_label[effectiveness]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py:182\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6406\u001b[0m, in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf):\n\u001b[0;32m-> 6406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36mencode_effectiveness_label\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_effectiveness_label\u001b[39m(df):\n\u001b[0;32m---> 10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39massign(discourse_effectiveness_ \u001b[38;5;241m=\u001b[39m \u001b[43mapply_new_label\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiscourse_effectiveness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m  )\n",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36mapply_new_label\u001b[0;34m(effectiveness)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_new_label\u001b[39m(effectiveness):\n\u001b[0;32m----> 8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnew_label\u001b[49m\u001b[43m[\u001b[49m\u001b[43meffectiveness\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [130]\u001b[0m, in \u001b[0;36m<cell line: 13>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mencode_effectiveness_label\u001b[39m(df):\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\u001b[38;5;241m.\u001b[39massign(discourse_effectiveness_ \u001b[38;5;241m=\u001b[39m apply_new_label(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscourse_effectiveness\u001b[39m\u001b[38;5;124m'\u001b[39m])  )\n\u001b[0;32m---> 13\u001b[0m ddf_out \u001b[38;5;241m=\u001b[39m \u001b[43mddf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencode_effectiveness_label\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:866\u001b[0m, in \u001b[0;36m_Frame.map_partitions\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;129m@insert_meta_param_description\u001b[39m(pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_partitions\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;124;03m\"\"\"Apply Python function on each DataFrame partition.\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \n\u001b[1;32m    743\u001b[0m \u001b[38;5;124;03m    Note that the index and divisions are assumed to remain unchanged.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m    None as the division.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 866\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6475\u001b[0m, in \u001b[0;36mmap_partitions\u001b[0;34m(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6468\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   6469\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt want the partitions to be aligned, and are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6470\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `map_partitions` directly, pass `align_dataframes=False`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6471\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   6473\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [df \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, _Frame)]\n\u001b[0;32m-> 6475\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[43m_get_meta_map_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Scalar) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m   6478\u001b[0m     layer \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   6479\u001b[0m         (name, \u001b[38;5;241m0\u001b[39m): (\n\u001b[1;32m   6480\u001b[0m             apply,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6484\u001b[0m         )\n\u001b[1;32m   6485\u001b[0m     }\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6587\u001b[0m, in \u001b[0;36m_get_meta_map_partitions\u001b[0;34m(args, dfs, func, kwargs, meta, parent_meta)\u001b[0m\n\u001b[1;32m   6583\u001b[0m     parent_meta \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_meta\n\u001b[1;32m   6584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m no_default:\n\u001b[1;32m   6585\u001b[0m     \u001b[38;5;66;03m# Use non-normalized kwargs here, as we want the real values (not\u001b[39;00m\n\u001b[1;32m   6586\u001b[0m     \u001b[38;5;66;03m# delayed values)\u001b[39;00m\n\u001b[0;32m-> 6587\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43m_emulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mudf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6588\u001b[0m     meta_is_emulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   6589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6406\u001b[0m, in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6402\u001b[0m \u001b[38;5;124;03mApply a function using args / kwargs. If arguments contain dd.DataFrame /\u001b[39;00m\n\u001b[1;32m   6403\u001b[0m \u001b[38;5;124;03mdd.Series, using internal cache (``_meta``) for calculation\u001b[39;00m\n\u001b[1;32m   6404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf):\n\u001b[0;32m-> 6406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m_extract_meta(args, \u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_extract_meta(kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    135\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py:203\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    194\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error is below:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m )\n\u001b[1;32m    202\u001b[0m msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m funcname \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(e), tb)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Metadata inference failed in `encode_effectiveness_label`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nTypeError(\"unhashable type: 'Series'\")\n\nTraceback:\n---------\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py\", line 182, in raise_on_meta_error\n    yield\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 6406, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/var/folders/9r/wxrt543d7gl3z6pgpy2pjpp80000gp/T/ipykernel_31814/2204620258.py\", line 10, in encode_effectiveness_label\n    return df.assign(discourse_effectiveness_ = apply_new_label(df['discourse_effectiveness'])  )\n  File \"/var/folders/9r/wxrt543d7gl3z6pgpy2pjpp80000gp/T/ipykernel_31814/2204620258.py\", line 8, in apply_new_label\n    return new_label[effectiveness]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ddf['essay'] = ddf['essay_id'].map_partitions(\n",
    "#     fetchEssay_ddf, root_src\n",
    "# )\n",
    "\n",
    "new_label = {\"Ineffective\": 0, \"Adequate\": 1, \"Effective\": 2}\n",
    "\n",
    "def encode_effectiveness_label(df):\n",
    "    return df.assign(discourse_effectiveness_ = apply_new_label(df['discourse_effectiveness'])  )\n",
    "\n",
    "def apply_new_label(effectiveness):\n",
    "    return new_label[effectiveness]\n",
    "\n",
    "ddf_out = ddf.map_partitions(encode_effectiveness_label) \n",
    "\n",
    "\n",
    "\n",
    "def fetchEssay_map(df):\n",
    "    return df.assign(essay_path = open_essay(df['essay_id']))\n",
    "\n",
    "def open_essay(essay_id):\n",
    "    full_path = ESSAY_ROOT_PATH + \"train/\" + essay_id + \".txt\"\n",
    "    print(\"opening essay: \" + essay_id)\n",
    "    print(\"opening full path: \" + full_path)\n",
    "    return (full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "575d831b-13c3-4a57-9427-dd49ad857550",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9857f41b-45bf-4988-aeb1-28904ef3ec9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_out\n",
    "result = ddf_out.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bba3178-7db8-419b-9202-6b22ff1edfc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f05452-faaf-4bed-9940-493add5a4935",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cd75d7-903d-4c17-a6e0-721cef184172",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a18c242-67e7-4c3d-b3d2-67093f053713",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede0aa48-183e-43e8-af62-f91f38682ab4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4471c3e-0d78-4076-8fb4-f8ea5319b321",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3722841d-e01b-4b95-a1dc-38085aea4a90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb97612-7df1-49d3-8281-b5b5d043c32b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8bed25-0081-4e5b-9e52-526be5bd2a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f619a41-df1f-41be-a7b9-84f09894a675",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a31225e-01d6-42c2-aa77-909babfc40fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014bd979-c17b-4d13-b736-612993138284",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "1fb19f4d-5eda-4acb-ba11-57f08d78000d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Metadata inference failed in `lambda`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nTypeError(\"unhashable type: 'Series'\")\n\nTraceback:\n---------\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py\", line 182, in raise_on_meta_error\n    yield\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 6406, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/var/folders/9r/wxrt543d7gl3z6pgpy2pjpp80000gp/T/ipykernel_31814/4069064272.py\", line 7, in <lambda>\n    lambda x: new_label[x]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py:182\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m    183\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6406\u001b[0m, in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf):\n\u001b[0;32m-> 6406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_extract_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [128]\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      5\u001b[0m new_label \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIneffective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdequate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEffective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[1;32m      6\u001b[0m ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscourse_effectiveness\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscourse_effectiveness\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmap_partitions(\n\u001b[0;32m----> 7\u001b[0m    \u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnew_label\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m \n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'Series'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [128]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ddf['essay'] = ddf['essay_id'].map_partitions(\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#     fetchEssay_ddf, root_src\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[1;32m      5\u001b[0m new_label \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIneffective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAdequate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEffective\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m2\u001b[39m}\n\u001b[0;32m----> 6\u001b[0m ddf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdiscourse_effectiveness\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;241m=\u001b[39m \u001b[43mddf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdiscourse_effectiveness\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m   \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_label\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:866\u001b[0m, in \u001b[0;36m_Frame.map_partitions\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[38;5;129m@insert_meta_param_description\u001b[39m(pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap_partitions\u001b[39m(\u001b[38;5;28mself\u001b[39m, func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    741\u001b[0m     \u001b[38;5;124;03m\"\"\"Apply Python function on each DataFrame partition.\u001b[39;00m\n\u001b[1;32m    742\u001b[0m \n\u001b[1;32m    743\u001b[0m \u001b[38;5;124;03m    Note that the index and divisions are assumed to remain unchanged.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[38;5;124;03m    None as the division.\u001b[39;00m\n\u001b[1;32m    865\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 866\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmap_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6475\u001b[0m, in \u001b[0;36mmap_partitions\u001b[0;34m(func, meta, enforce_metadata, transform_divisions, align_dataframes, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6468\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   6469\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. If you don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt want the partitions to be aligned, and are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6470\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcalling `map_partitions` directly, pass `align_dataframes=False`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   6471\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   6473\u001b[0m dfs \u001b[38;5;241m=\u001b[39m [df \u001b[38;5;28;01mfor\u001b[39;00m df \u001b[38;5;129;01min\u001b[39;00m args \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(df, _Frame)]\n\u001b[0;32m-> 6475\u001b[0m meta \u001b[38;5;241m=\u001b[39m \u001b[43m_get_meta_map_partitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdfs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparent_meta\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(arg, Scalar) \u001b[38;5;28;01mfor\u001b[39;00m arg \u001b[38;5;129;01min\u001b[39;00m args):\n\u001b[1;32m   6478\u001b[0m     layer \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   6479\u001b[0m         (name, \u001b[38;5;241m0\u001b[39m): (\n\u001b[1;32m   6480\u001b[0m             apply,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   6484\u001b[0m         )\n\u001b[1;32m   6485\u001b[0m     }\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6587\u001b[0m, in \u001b[0;36m_get_meta_map_partitions\u001b[0;34m(args, dfs, func, kwargs, meta, parent_meta)\u001b[0m\n\u001b[1;32m   6583\u001b[0m     parent_meta \u001b[38;5;241m=\u001b[39m dfs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_meta\n\u001b[1;32m   6584\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m meta \u001b[38;5;129;01mis\u001b[39;00m no_default:\n\u001b[1;32m   6585\u001b[0m     \u001b[38;5;66;03m# Use non-normalized kwargs here, as we want the real values (not\u001b[39;00m\n\u001b[1;32m   6586\u001b[0m     \u001b[38;5;66;03m# delayed values)\u001b[39;00m\n\u001b[0;32m-> 6587\u001b[0m     meta \u001b[38;5;241m=\u001b[39m \u001b[43m_emulate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mudf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6588\u001b[0m     meta_is_emulated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   6589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py:6406\u001b[0m, in \u001b[0;36m_emulate\u001b[0;34m(func, udf, *args, **kwargs)\u001b[0m\n\u001b[1;32m   6401\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6402\u001b[0m \u001b[38;5;124;03mApply a function using args / kwargs. If arguments contain dd.DataFrame /\u001b[39;00m\n\u001b[1;32m   6403\u001b[0m \u001b[38;5;124;03mdd.Series, using internal cache (``_meta``) for calculation\u001b[39;00m\n\u001b[1;32m   6404\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   6405\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m raise_on_meta_error(funcname(func), udf\u001b[38;5;241m=\u001b[39mudf):\n\u001b[0;32m-> 6406\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39m_extract_meta(args, \u001b[38;5;28;01mTrue\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_extract_meta(kwargs, \u001b[38;5;28;01mTrue\u001b[39;00m))\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    135\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraceback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py:203\u001b[0m, in \u001b[0;36mraise_on_meta_error\u001b[0;34m(funcname, udf)\u001b[0m\n\u001b[1;32m    194\u001b[0m msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOriginal error is below:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    201\u001b[0m )\n\u001b[1;32m    202\u001b[0m msg \u001b[38;5;241m=\u001b[39m msg\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m in `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m funcname \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mrepr\u001b[39m(e), tb)\n\u001b[0;32m--> 203\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Metadata inference failed in `lambda`.\n\nYou have supplied a custom function and Dask is unable to \ndetermine the type of output that that function returns. \n\nTo resolve this please provide a meta= keyword.\nThe docstring of the Dask function you ran should have more information.\n\nOriginal error is below:\n------------------------\nTypeError(\"unhashable type: 'Series'\")\n\nTraceback:\n---------\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/utils.py\", line 182, in raise_on_meta_error\n    yield\n  File \"/opt/anaconda3/lib/python3.9/site-packages/dask/dataframe/core.py\", line 6406, in _emulate\n    return func(*_extract_meta(args, True), **_extract_meta(kwargs, True))\n  File \"/var/folders/9r/wxrt543d7gl3z6pgpy2pjpp80000gp/T/ipykernel_31814/4069064272.py\", line 7, in <lambda>\n    lambda x: new_label[x]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c91983-0ae3-44e8-9d46-4f752c2c5edb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "296fb295-eea3-402e-b704-5af9a901d2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6894d2-c4e4-407c-81ae-3e705750a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "# https://www.kaggle.com/code/arvissu/roberta-base-training-notebook-1-epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9135e-6bb3-463d-9447-ffac6daf9f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_list = list()\n",
    "kf = StratifiedKFold(n_splits=FOLDS)\n",
    "for i, (train_idx, valid_idx) in enumerate(kf.split(df, y=df['essay_id'])):\n",
    "    print(f'fold {i+1}')\n",
    "    gc.collect()\n",
    "    \n",
    "    cb = callback()\n",
    "    train_loader = torch.utils.data.DataLoader(FeedBackDataset(df.loc[train_idx, :].reset_index(drop=True), model_path), batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
    "    val_loader = torch.utils.data.DataLoader(FeedBackDataset(df.loc[valid_idx, :].reset_index(drop=True), model_path), batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n",
    "    \n",
    "    \n",
    "    net = FeedBackModel(model_path)\n",
    "    net.cuda()\n",
    "    \n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(net.parameters(), lr = lr)    \n",
    "    param_optimizer = list(net.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "    num_train_optimization_steps = int(EPOCHS * len(train_loader) / accumulation_steps)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0.05 * num_train_optimization_steps,\n",
    "                                                num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    \n",
    "    for epoch in range(EPOCHS):  \n",
    "\n",
    "        start_time = time.time()\n",
    "        avg_loss = 0.0\n",
    "        net.train()\n",
    "        tbar = tqdm(train_loader, file=sys.stdout)\n",
    "        loss_list = []\n",
    "        val_loss_list = []\n",
    "        \n",
    "        for step, data in enumerate(tbar):\n",
    "\n",
    "            # get the inputs\n",
    "            input_ids = data['ids'].cuda()\n",
    "            input_masks = data['mask'].cuda()\n",
    "            targets = data['targets'].long().view(-1).cuda()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                pred = net(input_ids,input_masks)\n",
    "                loss = loss_fn(pred, targets)\n",
    "                \n",
    "            scaler.scale(loss).backward()\n",
    "            \n",
    "\n",
    "            if step % accumulation_steps == 0 or step == len(tbar) - 1:\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "                scheduler.step()\n",
    "                \n",
    "            loss_list.append(loss.detach().cpu().item())\n",
    "            avg_loss = np.round(np.mean(loss_list), 4)\n",
    "\n",
    "            tbar.set_description(f\"Epoch {epoch + 1} Loss: {avg_loss} lr: {scheduler.get_last_lr()}\")\n",
    "        \n",
    "        net.eval()\n",
    "        avg_val_loss = 0.0   \n",
    "        tbar_val = tqdm(val_loader, file=sys.stdout)\n",
    "        for step, data in enumerate(tbar_val):\n",
    "\n",
    "            # get the inputs\n",
    "            input_ids = data['ids'].cuda()\n",
    "            input_masks = data['mask'].cuda()\n",
    "            targets = data['targets'].long().view(-1).cuda()\n",
    "            \n",
    "            pred = net(input_ids,input_masks)\n",
    "            loss = loss_fn(pred, targets)\n",
    "                \n",
    "            val_loss_list.append(loss.detach().cpu().item())\n",
    "            avg_val_loss = np.round(np.mean(val_loss_list), 4)\n",
    "\n",
    "            tbar_val.set_description(f\"Epoch {epoch + 1} Loss: {avg_val_loss}\")\n",
    "                    \n",
    "        cb.put(net, avg_val_loss)   \n",
    "        \n",
    "    model_list.append(cb.get_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6451af95-11b8-43fe-be79-07e6991da4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Done generating a model.\n",
    "model_target = \"roberta_modellist.pkl\"\n",
    "with open(model_target,\"wb\") as f:\n",
    "    pickle.dump(model_list, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d1e96d-a759-4adb-825b-0fac657bc007",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infer\n",
    "# https://www.kaggle.com/code/arvissu/roberta-base-inference-v2-0/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11f534bb-47c8-4736-86de-1d59b1cae7d9",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m BATCH_SIZE \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m32\u001b[39m\n\u001b[1;32m      3\u001b[0m MAX_LEN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m----> 6\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mDataLoader(FeedBackDataset(test_df, tokenizer, \u001b[38;5;28;01mTrue\u001b[39;00m), batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m model_list \u001b[38;5;241m=\u001b[39m pickle\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mopen\u001b[39m(model_target, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m test_pred \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(test_df), \u001b[38;5;241m3\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "NFOLDS = 5\n",
    "BATCH_SIZE = 32\n",
    "MAX_LEN = 512\n",
    "\n",
    "\n",
    "model_list = pickle.load(open(model_target, \"rb\"))\n",
    "test_pred = np.zeros((len(test_df), 3))\n",
    "\n",
    "# test_df = pd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")\n",
    "test_ddf = dd.read_csv(\"../input/feedback-prize-effectiveness/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c268fc6-0d2d-42a3-b061-e5400912fba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def predict(test_df: pd.DataFrame, tokenizer, result):\n",
    "    test_loader = torch.utils.data.DataLoader(FeedBackDataset(test_df, tokenizer, True), batch_size=BATCH_SIZE, shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(test_loader):\n",
    "            input_ids = data['ids'].cuda()\n",
    "            input_masks = data['mask'].cuda()\n",
    "            pred = F.softmax(net(input_ids,input_masks))\n",
    "            result.extend(pred.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85307221-5ec8-4a70-8627-3873694ad800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mika's note: K-folds is a fairly parallel work as the each batch in folds are normalized to have data parallelism.\n",
    "# Idea hers is to use dask dataframe to handle that part.\n",
    "\n",
    "for idx in range(NFOLDS):\n",
    "    print(f'start to inference fold : {idx}')\n",
    "    net = model_list[idx]\n",
    "    net.eval()\n",
    "    net.cuda()\n",
    "    result = list()\n",
    "    predict(test_ddf, tokenizer, result)\n",
    "    test_pred += np.array(result)/NFOLDS\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7b2178-6cae-4725-9244-7a6e3f0036db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for idx in range(NFOLDS):\n",
    "#     print(f'start to inference fold : {idx}')\n",
    "#     net = model_list[idx]\n",
    "#     net.eval()\n",
    "#     net.cuda()\n",
    "#     result = list()\n",
    "#     with torch.no_grad():\n",
    "#         for i, data in enumerate(test_loader):\n",
    "#             input_ids = data['ids'].cuda()\n",
    "#             input_masks = data['mask'].cuda()\n",
    "#             pred = F.softmax(net(input_ids,input_masks))\n",
    "#             result.extend(pred.cpu().detach().numpy())\n",
    "#     test_pred += np.array(result)/NFOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5983743d-a318-4ba1-bf5d-dcab75b15806",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is our test set predictions\n",
    "test_pred\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
